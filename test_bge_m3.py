#!/usr/bin/env python3
"""
ê²½ëŸ‰ ì„ë² ë”© ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ë° í…ŒìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸
"""

import os
import json
import numpy as np
from llama_cpp import Llama
from huggingface_hub import model_info, hf_hub_download
from konlpy.tag import Okt

def test_lightweight_model():
    """ê²½ëŸ‰ ì„ë² ë”© ëª¨ë¸ ë¡œë“œ ë° ê¸°ë³¸ í…ŒìŠ¤íŠ¸"""
    
    print("ğŸš€ ê²½ëŸ‰ ì„ë² ë”© ëª¨ë¸ í…ŒìŠ¤íŠ¸ ì‹œì‘")
    print("=" * 50)
    
    try:
        # GGUF ëª¨ë¸ ì •ë³´ í™•ì¸ (puppyM ëª¨ë¸ ì‚¬ìš©)
        model_repo = 'puppyM/bge-m3-Q4_K_M-GGUF'
        model_filename = 'bge-m3-q4_k_m.gguf'  # ì†Œë¬¸ì!
        
        print("ğŸ“Š GGUF ëª¨ë¸ ì •ë³´ í™•ì¸ ì¤‘...")
        try:
            info = model_info(model_repo)
            print(f"ğŸ’¾ ì˜ˆìƒ ëª¨ë¸ í¬ê¸°: ~600MB (Q4_K_M ì–‘ìí™”)")
        except Exception as e:
            print(f"âš ï¸ ëª¨ë¸ ì •ë³´ í™•ì¸ ì‹¤íŒ¨: {e}")
        
        # GGUF ëª¨ë¸ ë‹¤ìš´ë¡œë“œ
        print("ğŸ“¥ GGUF ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ì¤‘... (ìµœì´ˆ ì‹¤í–‰ ì‹œ)")
        try:
            model_path = hf_hub_download(
                repo_id=model_repo,
                filename=model_filename,
                cache_dir="./models"
            )
            print(f"âœ… ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ì™„ë£Œ: {model_path}")
        except Exception as e:
            print(f"âŒ ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨: {e}")
            return False
        
        # llama-cppë¡œ ëª¨ë¸ ë¡œë“œ
        print("ğŸ”§ GGUF ëª¨ë¸ ë¡œë“œ ì¤‘...")
        model = Llama(
            model_path=model_path,
            embedding=True,  # ì„ë² ë”© ëª¨ë“œ
            verbose=False,
            n_ctx=512,  # ì»¨í…ìŠ¤íŠ¸ ê¸¸ì´
            n_threads=4  # CPU ìŠ¤ë ˆë“œ ìˆ˜
        )
        print("âœ… ëª¨ë¸ ë¡œë“œ ì™„ë£Œ!")
        print(f"ğŸ“Š ëª¨ë¸ ì •ë³´: BGE-M3 Q4_K_M ì–‘ìí™” (768ì°¨ì› ì˜ˆìƒ)")
        
        # í…ŒìŠ¤íŠ¸ í…ìŠ¤íŠ¸
        test_texts = [
            "3ê°œì›” ë‚´ì— 5km ëŸ¬ë‹ì„ 30ë¶„ ë‚´ì— ì™„ì£¼í•˜ê¸°",
            "í•œ ë‹¬ ì•ˆì— ì˜ì–´ ë©´ì ‘ ì™„ë²½ ëŒ€ë¹„í•˜ê¸°",
            "íŒŒì´ì¬ í”„ë¡œê·¸ë˜ë° ê¸°ì´ˆë¶€í„° ê³ ê¸‰ê¹Œì§€ ë§ˆìŠ¤í„°í•˜ê¸°",
            "í† ìµ 900ì  ë‹¬ì„±ì„ ìœ„í•œ ì²´ê³„ì  í•™ìŠµ ê³„íš"
        ]
        
        print(f"\nğŸ“ í…ŒìŠ¤íŠ¸ í…ìŠ¤íŠ¸ ({len(test_texts)}ê°œ):")
        for i, text in enumerate(test_texts, 1):
            print(f"  {i}. {text}")
        
        # GGUF ëª¨ë¸ë¡œ ì„ë² ë”© ìƒì„±
        print(f"\nğŸ”„ ì„ë² ë”© ìƒì„± ì¤‘...")
        embeddings = []
        for i, text in enumerate(test_texts):
            print(f"  ì²˜ë¦¬ ì¤‘: {i+1}/{len(test_texts)}")
            embedding = model.create_embedding(text)
            embeddings.append(embedding['data'][0]['embedding'])
        
        embeddings = np.array(embeddings)
        
        # ê²°ê³¼ ë¶„ì„
        print(f"\nğŸ“Š ì„ë² ë”© ê²°ê³¼:")
        print(f"  Dense ë²¡í„° shape: {embeddings.shape}")
        print(f"  Dense ë²¡í„° íƒ€ì…: {type(embeddings)}")
        print(f"  ë²¡í„° ì°¨ì›: {embeddings.shape[1]}")
        
        # Dense ë²¡í„° ì˜ˆì‹œ ì¶œë ¥
        print(f"\nğŸ” Dense ë²¡í„° ì˜ˆì‹œ (ì²« ë²ˆì§¸ í…ìŠ¤íŠ¸, ì²˜ìŒ 10ê°œ ê°’):")
        dense_sample = embeddings[0][:10]
        print(f"  {dense_sample}")
        
        # KoNLPyë¡œ ì‹¤ì œ í‚¤ì›Œë“œ ì¶”ì¶œ
        print(f"\nğŸ” KoNLPy í‚¤ì›Œë“œ ì¶”ì¶œ í…ŒìŠ¤íŠ¸:")
        okt = Okt()
        
        for i, text in enumerate(test_texts):
            # ëª…ì‚¬ ì¶”ì¶œ
            nouns = okt.nouns(text)
            # í˜•íƒœì†Œ ë¶„ì„ (í’ˆì‚¬ íƒœê¹…)
            morphs = okt.pos(text)
            
            print(f"\n  í…ìŠ¤íŠ¸ {i+1}: {text}")
            print(f"  ëª…ì‚¬: {nouns}")
            print(f"  ì£¼ìš” í˜•íƒœì†Œ: {[word for word, pos in morphs if pos in ['Noun', 'Verb', 'Adjective']][:5]}")
            
            if i == 0:  # ì²« ë²ˆì§¸ë§Œ ìì„¸íˆ
                break
        
        # ìœ ì‚¬ë„ í…ŒìŠ¤íŠ¸
        print(f"\nğŸ¯ ìœ ì‚¬ë„ í…ŒìŠ¤íŠ¸:")
        
        # ì²« ë²ˆì§¸ì™€ ë‘ ë²ˆì§¸ í…ìŠ¤íŠ¸ ê°„ ì½”ì‚¬ì¸ ìœ ì‚¬ë„
        vec1 = embeddings[0]
        vec2 = embeddings[1]
        
        cosine_sim = np.dot(vec1, vec2) / (np.linalg.norm(vec1) * np.linalg.norm(vec2))
        print(f"  'ëŸ¬ë‹' vs 'ì˜ì–´ë©´ì ‘' ìœ ì‚¬ë„: {cosine_sim:.4f}")
        
        vec3 = embeddings[2]
        cosine_sim2 = np.dot(vec1, vec3) / (np.linalg.norm(vec1) * np.linalg.norm(vec3))
        print(f"  'ëŸ¬ë‹' vs 'íŒŒì´ì¬' ìœ ì‚¬ë„: {cosine_sim2:.4f}")
        
        # MariaDB ì €ì¥ í˜•íƒœ ì˜ˆì‹œ
        print(f"\nğŸ’¾ MariaDB ì €ì¥ í˜•íƒœ ì˜ˆì‹œ:")
        
        # Dense ë²¡í„°ë¥¼ ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜ (MariaDB VECTOR íƒ€ì…ìš©)
        dense_for_db = embeddings[0].tolist()
        print(f"  Dense ë²¡í„° ê¸¸ì´: {len(dense_for_db)}")
        print(f"  Dense ë²¡í„° íƒ€ì…: {type(dense_for_db)}")
        
        # KoNLPy ê²°ê³¼ë¥¼ MariaDB JSON í˜•íƒœë¡œ ë³€í™˜
        okt_analyzer = Okt()  # ìƒˆë¡œ ìƒì„±
        first_text_nouns = okt_analyzer.nouns(test_texts[0])
        sparse_for_db = {
            "keywords": ", ".join(first_text_nouns),
            "weights": {noun: 1.0 for noun in first_text_nouns},  # ë‹¨ìˆœ ê°€ì¤‘ì¹˜
            "extraction_method": "konlpy_okt",
            "pos_tags": dict(okt_analyzer.pos(test_texts[0])[:5])  # ìƒìœ„ 5ê°œ í’ˆì‚¬
        }
        print(f"  Sparse JSON ì˜ˆì‹œ: {json.dumps(sparse_for_db, indent=2, ensure_ascii=False)}")
        
        print("\n" + "=" * 50)
        print("ğŸ‰ í•œêµ­ì–´ íŠ¹í™” BGE-M3 ëª¨ë¸ í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")
        print("âœ… ëª¨ë¸ì´ ì •ìƒì ìœ¼ë¡œ ì‘ë™í•©ë‹ˆë‹¤.")
        print("âœ… Dense ì„ë² ë”© ìƒì„± í™•ì¸")
        print("âœ… í‚¤ì›Œë“œ ì¶”ì¶œ ì‹œë®¬ë ˆì´ì…˜ í™•ì¸")
        print("âœ… MariaDB ì €ì¥ í˜•íƒœ ë³€í™˜ í™•ì¸")
        print(f"ğŸ“Š ëª¨ë¸: ONNX ìµœì í™” + í•œêµ­ì–´ íŠ¹í™”")
        print(f"ğŸ”§ DB ìŠ¤í‚¤ë§ˆ ìˆ˜ì • í•„ìš”: VECTOR({embeddings.shape[1]}) ì°¨ì›")
        
        return True
        
    except Exception as e:
        print(f"\nâŒ í…ŒìŠ¤íŠ¸ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        print("ğŸ” ë‹¤ìŒì„ í™•ì¸í•˜ì„¸ìš”:")
        print("   1. í•„ìš”í•œ íŒ¨í‚¤ì§€ê°€ ëª¨ë‘ ì„¤ì¹˜ë˜ì—ˆëŠ”ì§€")
        print("   2. ì¸í„°ë„· ì—°ê²°ì´ ì •ìƒì¸ì§€ (ëª¨ë¸ ë‹¤ìš´ë¡œë“œìš©)")
        print("   3. ì¶©ë¶„í•œ ë””ìŠ¤í¬ ê³µê°„ì´ ìˆëŠ”ì§€")
        return False

if __name__ == "__main__":
    success = test_lightweight_model()
    if not success:
        exit(1)
