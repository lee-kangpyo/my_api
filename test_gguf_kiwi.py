#!/usr/bin/env python3
"""
GGUF + Kiwi ì¡°í•© í…ŒìŠ¤íŠ¸
"""

import os
import json
import numpy as np
from llama_cpp import Llama
from huggingface_hub import model_info, hf_hub_download
from kiwipiepy import Kiwi

def test_gguf_kiwi():
    """GGUF + Kiwi ì¡°í•© í…ŒìŠ¤íŠ¸"""
    
    print("ğŸš€ GGUF + Kiwi ì¡°í•© í…ŒìŠ¤íŠ¸ ì‹œì‘")
    print("=" * 50)
    
    try:
        # 1. GGUF ëª¨ë¸ ì¤€ë¹„
        model_repo = 'puppyM/bge-m3-Q4_K_M-GGUF'
        model_filename = 'bge-m3-q4_k_m.gguf'
        
        print("ğŸ“Š GGUF ëª¨ë¸ ì¤€ë¹„ ì¤‘...")
        model_path = hf_hub_download(
            repo_id=model_repo,
            filename=model_filename,
            cache_dir="./models"
        )
        
        gguf_model = Llama(
            model_path=model_path,
            embedding=True,
            verbose=False,
            n_ctx=512,
            n_threads=4
        )
        print("âœ… GGUF ëª¨ë¸ ë¡œë“œ ì™„ë£Œ!")
        
        # 2. Kiwi í˜•íƒœì†Œ ë¶„ì„ê¸° ì¤€ë¹„
        print("ğŸ¥ Kiwi í˜•íƒœì†Œ ë¶„ì„ê¸° ë¡œë“œ ì¤‘...")
        kiwi = Kiwi()
        print("âœ… Kiwi ë¡œë“œ ì™„ë£Œ!")
        
        # 3. í…ŒìŠ¤íŠ¸ í…ìŠ¤íŠ¸
        test_texts = [
            "3ê°œì›” ë‚´ì— 5km ëŸ¬ë‹ì„ 30ë¶„ ë‚´ì— ì™„ì£¼í•˜ê¸°",
            "í•œ ë‹¬ ì•ˆì— ì˜ì–´ ë©´ì ‘ ì™„ë²½ ëŒ€ë¹„í•˜ê¸°",
            "íŒŒì´ì¬ í”„ë¡œê·¸ë˜ë° ê¸°ì´ˆë¶€í„° ê³ ê¸‰ê¹Œì§€ ë§ˆìŠ¤í„°í•˜ê¸°"
        ]
        
        print(f"\nğŸ“ í…ŒìŠ¤íŠ¸ í…ìŠ¤íŠ¸ ({len(test_texts)}ê°œ):")
        for i, text in enumerate(test_texts, 1):
            print(f"  {i}. {text}")
        
        # 4. Dense ë²¡í„° ìƒì„± (GGUF)
        print(f"\nğŸ”„ Dense ë²¡í„° ìƒì„± ì¤‘...")
        embeddings = []
        for i, text in enumerate(test_texts):
            print(f"  ì²˜ë¦¬ ì¤‘: {i+1}/{len(test_texts)}")
            embedding = gguf_model.create_embedding(text)
            embeddings.append(embedding['data'][0]['embedding'])
        
        embeddings = np.array(embeddings)
        print(f"âœ… Dense ë²¡í„° ìƒì„± ì™„ë£Œ: {embeddings.shape}")
        
        # 5. Sparse í‚¤ì›Œë“œ ì¶”ì¶œ (Kiwi)
        print(f"\nğŸ¥ Kiwi í‚¤ì›Œë“œ ì¶”ì¶œ í…ŒìŠ¤íŠ¸:")
        
        for i, text in enumerate(test_texts):
            print(f"\n  í…ìŠ¤íŠ¸ {i+1}: {text}")
            
            # ëª…ì‚¬ ì¶”ì¶œ
            result = kiwi.analyze(text)
            nouns = [token.form for token in result[0][0] if token.tag.startswith('N')]
            print(f"  ëª…ì‚¬: {nouns}")
            
            # ê°„ë‹¨í•œ í† í°í™”
            tokens = kiwi.tokenize(text)
            meaningful_tokens = [token.form for token in tokens if len(token.form) > 1]
            print(f"  ì˜ë¯¸ìˆëŠ” í† í°: {meaningful_tokens[:8]}")
            
            if i == 0:  # ì²« ë²ˆì§¸ë§Œ ìì„¸íˆ
                break
        
        # 6. MariaDB ì €ì¥ í˜•íƒœ ì˜ˆì‹œ
        print(f"\nğŸ’¾ MariaDB ì €ì¥ í˜•íƒœ ì˜ˆì‹œ:")
        
        # Dense ë²¡í„°
        dense_for_db = embeddings[0].tolist()
        print(f"  Dense ë²¡í„° ê¸¸ì´: {len(dense_for_db)}")
        print(f"  Dense ë²¡í„° ì°¨ì›: {len(dense_for_db)}")
        
        # Sparse í‚¤ì›Œë“œ (Kiwi)
        first_text_result = kiwi.analyze(test_texts[0])
        first_text_nouns = [token.form for token in first_text_result[0][0] if token.tag.startswith('N')]
        
        sparse_for_db = {
            "keywords": ", ".join(first_text_nouns),
            "weights": {noun: 1.0 for noun in first_text_nouns},
            "extraction_method": "kiwi",
            "total_tokens": len(first_text_result[0][0])
        }
        print(f"  Sparse JSON ì˜ˆì‹œ:")
        print(f"  {json.dumps(sparse_for_db, indent=2, ensure_ascii=False)}")
        
        # 7. ìœ ì‚¬ë„ í…ŒìŠ¤íŠ¸
        vec1 = embeddings[0]
        vec2 = embeddings[1]
        cosine_sim = np.dot(vec1, vec2) / (np.linalg.norm(vec1) * np.linalg.norm(vec2))
        print(f"\nğŸ¯ ìœ ì‚¬ë„ í…ŒìŠ¤íŠ¸:")
        print(f"  'ëŸ¬ë‹' vs 'ì˜ì–´ë©´ì ‘' ìœ ì‚¬ë„: {cosine_sim:.4f}")
        
        print("\n" + "=" * 50)
        print("ğŸ‰ GGUF + Kiwi ì¡°í•© í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")
        print("âœ… Dense ë²¡í„° ìƒì„± ì„±ê³µ (GGUF)")
        print("âœ… Sparse í‚¤ì›Œë“œ ì¶”ì¶œ ì„±ê³µ (Kiwi)")
        print("âœ… MariaDB ì €ì¥ í˜•íƒœ ë³€í™˜ í™•ì¸")
        print(f"ğŸ“Š ì´ ì‹œìŠ¤í…œ í¬ê¸°: ~460MB (GGUF 438MB + Kiwi ~20MB)")
        
        return True
        
    except Exception as e:
        print(f"\nâŒ í…ŒìŠ¤íŠ¸ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        import traceback
        traceback.print_exc()
        return False

if __name__ == "__main__":
    success = test_gguf_kiwi()
    if not success:
        exit(1)
