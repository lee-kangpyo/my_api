from fastapi import APIRouter, Depends, HTTPException, status
from sqlalchemy.orm import Session
from database import get_smallstep_db
from pydantic import BaseModel
from typing import List, Optional
import google.generativeai as genai
import os
import logging
from prompts.goal_analysis import create_goal_analysis_prompt
from prompts.feedback import create_feedback_prompt
from schemas.smallstep.activities import Activity
from datetime import datetime
from services.core import GoalValidationService

import re
import json

logger = logging.getLogger(__name__)

# ì„œë¹„ìŠ¤ ì´ˆê¸°í™”
goal_validation_service = GoalValidationService()

router = APIRouter(
    prefix="/api/smallstep",
    tags=["SmallStep - LLM ì„œë¹„ìŠ¤"]
)

# Google AI ì„¤ì •
GOOGLE_API_KEY = os.getenv("GOOGLE_API_KEY")
if GOOGLE_API_KEY:
    try:
        genai.configure(api_key=GOOGLE_API_KEY)
        # ìµœì‹  ê¶Œì¥ ëª¨ë¸ ì‚¬ìš©
        model = genai.GenerativeModel('gemini-2.0-flash-lite')
        logger.info("Google AI ëª¨ë¸ ì´ˆê¸°í™” ì„±ê³µ: gemini-2.0-flash-lite")
    except Exception as e:
        logger.error(f"gemini-2.0-flash-lite ì‹¤íŒ¨: {e}")
        # ëŒ€ì•ˆ ëª¨ë¸ ì‹œë„
        try:
            model = genai.GenerativeModel('gemini-2.0-flash')
            logger.info("ëŒ€ì•ˆ ëª¨ë¸ ì‚¬ìš©: gemini-2.0-flash")
        except Exception as e2:
            logger.error(f"gemini-2.0-flashë„ ì‹¤íŒ¨: {e2}")
            # ìµœí›„ì˜ ìˆ˜ë‹¨: 1.5 ë²„ì „
            try:
                model = genai.GenerativeModel('gemini-1.5-flash-002')
                logger.info("ìµœí›„ ëª¨ë¸ ì‚¬ìš©: gemini-1.5-flash-002")
            except Exception as e3:
                logger.error(f"ëª¨ë“  ëª¨ë¸ ì‹¤íŒ¨: {e3}")
                model = None
else:
    logger.warning("GOOGLE_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•ŠìŒ")
    model = None

from schemas.smallstep.llm import GoalAnalysisRequest, RoadmapPhase, GoalAnalysisResponse


class AIFeedbackRequest(BaseModel):
    user_id: int
    goal_id: int
    completed_activities: List[str]
    current_progress: float

class AIFeedbackResponse(BaseModel):
    feedback_message: str
    next_steps: List[str]
    motivation_quote: str
    progress_analysis: str

@router.post("/llm/analyze-goal", response_model=GoalAnalysisResponse,
             summary="ëª©í‘œ ë¶„ì„ ë° í™œë™ ê³„íš ìƒì„±",
             description="""
LLMì„ ì‚¬ìš©í•˜ì—¬ ì‚¬ìš©ìì˜ ëª©í‘œë¥¼ ë¶„ì„í•˜ê³  í™œë™ ê³„íšì„ ìƒì„±í•©ë‹ˆë‹¤.

**ê¸°ëŠ¥:**
- ëª©í‘œ ë¶„ì„ ë° ë‚œì´ë„ í‰ê°€
- ë‹¨ê³„ë³„ í™œë™ ê³„íš ìƒì„±
- ì˜ˆìƒ ì†Œìš” ì‹œê°„ ê³„ì‚°
- ë™ê¸°ë¶€ì—¬ íŒ ì œê³µ

**ìš”ì²­ ì˜ˆì‹œ:**
```json
{
  "goal": "ì˜ì–´ íšŒí™”",
  "duration_weeks": 6,
  "weekly_frequency": 4
}
```
""")
async def analyze_goal(request: GoalAnalysisRequest, db: Session = Depends(get_smallstep_db)):
    """ëª©í‘œ ë¶„ì„ ë° í™œë™ ê³„íš ìƒì„±"""

    # ëª©í‘œ ê²€ì¦ (3ë‹¨ê³„ í•„í„°ë§)
    validation_passed, validation_message, validation_info = await goal_validation_service.validate_goal(request.goal)
    
    if not validation_passed:
        raise HTTPException(
            status_code=status.HTTP_400_BAD_REQUEST,
            detail=validation_message
        )
    
    if not model:
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail="Google AI API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."
        )
    
    try:
        # ê¸°ì¡´ í”„ë¡¬í”„íŠ¸ í•¨ìˆ˜ ì‚¬ìš©
        prompt = create_goal_analysis_prompt(
            goal=request.goal,
            duration_weeks=request.duration_weeks,
            weekly_frequency=request.weekly_frequency
        )
        
        # ë‹¨ í•œ ë²ˆì˜ ë…ë¦½ì ì¸ API í˜¸ì¶œ
        response = model.generate_content(prompt)
        
        # JSON ì‘ë‹µ íŒŒì‹±
        try:
            content = response.text.strip()
            print(f"ğŸ” LLM ì›ë³¸ ì‘ë‹µ: {content}")
            print(f"ğŸ” ì‘ë‹µ ê¸¸ì´: {len(content)}")
            
            if not content:
                raise ValueError("LLM ì‘ë‹µì´ ë¹„ì–´ìˆìŠµë‹ˆë‹¤.")
            
            # JSON ë¶€ë¶„ë§Œ ì¶”ì¶œ (```json ... ``` í˜•íƒœì¼ ê²½ìš°)
            if "```json" in content:
                start = content.find("```json") + 7
                end = content.find("```", start)
                json_str = content[start:end].strip()
            elif "```" in content:
                # ```jsonì´ ì—†ì§€ë§Œ ```ê°€ ìˆëŠ” ê²½ìš°
                start = content.find("```") + 3
                end = content.find("```", start)
                json_str = content[start:end].strip()
            else:
                json_str = content
            
            print(f"ğŸ” ì¶”ì¶œëœ JSON: {json_str[:100]}...")
            
            result = json.loads(json_str)

            # ë¡œê·¸ì—ë„ ê¸°ë¡
            logger.info(f"LLM Response Length: {len(content)}")
            logger.info(f"LLM Response: {content}")

            # Activity ìŠ¤í‚¤ë§ˆì— ë§ê²Œ ë³€í™˜
            activities = []
            for item in result["schedule"]:
                activities.append(Activity(
                    week=item["week"],
                    day=item["day"],
                    phase_link=item["phase_link"],
                    activity_type=item["activity_type"],
                    title=item["title"],
                    description=item["description"],
                    goal_id=0,  # ì„ì‹œê°’, ì‹¤ì œë¡œëŠ” goal_id í•„ìš”
                    id=0,  # ì„ì‹œê°’
                    created_at=datetime.now()  # í˜„ì¬ ì‹œê°„ìœ¼ë¡œ ì„¤ì •
                ))
            
            # SS_CACHED_PLANS ì €ì¥ ë¡œì§ (save_to_cacheê°€ Trueì¼ ë•Œë§Œ)
            if request.save_to_cache:
                try:
                    print(f"SS_CACHED_PLANS ì €ì¥ ì‹œì‘: {request.goal}")
                    
                    # ì„œë¹„ìŠ¤ ë ˆì´ì–´ë¥¼ í†µí•œ ì €ì¥
                    from services.core import CachedPlanService
                    cached_plan_service = CachedPlanService()
                    
                    plan_id = cached_plan_service.save_cached_plan(
                        goal=request.goal,
                        duration_weeks=request.duration_weeks,
                        weekly_frequency=request.weekly_frequency,
                        roadmap=result["roadmap"],
                        schedule=result["schedule"],
                        db=db
                    )
                    
                    if plan_id:
                        print(f"âœ… SS_CACHED_PLANS ì €ì¥ ì™„ë£Œ: {plan_id}")
                    else:
                        print(f"âŒ SS_CACHED_PLANS ì €ì¥ ì‹¤íŒ¨")
                    
                except Exception as e:
                    print(f"âŒ SS_CACHED_PLANS ì €ì¥ ì‹¤íŒ¨: {e}")
                    logger.error(f"Cached plan save failed: {str(e)}")
                    # ì €ì¥ ì‹¤íŒ¨í•´ë„ API ì‘ë‹µì€ ì •ìƒ ë°˜í™˜
            
            return GoalAnalysisResponse(
                roadmap=result["roadmap"],
                schedule=activities
            )
            
        except (json.JSONDecodeError, KeyError) as e:
            logger.error(f"JSON parsing failed: {str(e)}")
            raise HTTPException(
                status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
                detail="LLM ì‘ë‹µ íŒŒì‹± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."
            )
        
    except Exception as e:
        logger.error(f"Goal analysis failed: {str(e)}")
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail="ëª©í‘œ ë¶„ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."
        )

@router.post("/llm/generate-feedback", response_model=AIFeedbackResponse,
             summary="AI í”¼ë“œë°± ìƒì„±",
             description="""
ì‚¬ìš©ìì˜ ì§„í–‰ ìƒí™©ì„ ë¶„ì„í•˜ê³  AI í”¼ë“œë°±ì„ ìƒì„±í•©ë‹ˆë‹¤.

**ê¸°ëŠ¥:**
- ì§„í–‰ ìƒí™© ë¶„ì„
- ê²©ë ¤ ë©”ì‹œì§€ ìƒì„±
- ë‹¤ìŒ ë‹¨ê³„ ì œì•ˆ
- ë™ê¸°ë¶€ì—¬ ëª…ì–¸ ì œê³µ

**ìš”ì²­ ì˜ˆì‹œ:**
```json
{
  "user_id": 1,
  "goal_id": 1,
  "completed_activities": ["ì˜ì–´ ë‹¨ì–´ 50ê°œ ì™¸ìš°ê¸°", "ë¬¸ë²• ê³µë¶€"],
  "current_progress": 30.5
}
```
""")
def generate_feedback(request: AIFeedbackRequest, db: Session = Depends(get_smallstep_db)):
    """AI í”¼ë“œë°± ìƒì„±"""
    if not model:
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail="Google AI API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."
        )
    
    try:
        # ê¸°ì¡´ í”„ë¡¬í”„íŠ¸ í•¨ìˆ˜ ì‚¬ìš©
        prompt = create_feedback_prompt(
            completed_activities=request.completed_activities,
            current_progress=request.current_progress
        )
        
        # ë‹¨ í•œ ë²ˆì˜ ë…ë¦½ì ì¸ API í˜¸ì¶œ
        response = model.generate_content(prompt)
        
        # JSON ì‘ë‹µ íŒŒì‹±
        try:
            import json
            content = response.text.strip()
            
            # ë””ë²„ê¹…ì„ ìœ„í•´ ì‹¤ì œ ì‘ë‹µ ë¡œê·¸ ì¶œë ¥
            logger.info(f"LLM Response: {content}")
            
            # JSON ë¶€ë¶„ë§Œ ì¶”ì¶œ (```json ... ``` í˜•íƒœì¼ ê²½ìš°)
            if "```json" in content:
                start = content.find("```json") + 7
                end = content.find("```", start)
                json_str = content[start:end].strip()
            elif "```" in content:
                # ```jsonì´ ì—†ì§€ë§Œ ```ê°€ ìˆëŠ” ê²½ìš°
                start = content.find("```") + 3
                end = content.find("```", start)
                json_str = content[start:end].strip()
            else:
                json_str = content
            
            # ë””ë²„ê¹…ì„ ìœ„í•´ ì¶”ì¶œëœ JSON ë¡œê·¸ ì¶œë ¥
            logger.info(f"Extracted JSON: {json_str}")
            
            # JSON ë¬¸ìì—´ ì •ë¦¬ (ë¶ˆí•„ìš”í•œ ë¬¸ì ì œê±°)
            json_str = json_str.replace('\n', ' ').replace('\r', ' ').strip()
            
            # JSON íŒŒì‹±
            result = json.loads(json_str)
            
            return AIFeedbackResponse(
                feedback_message=result["feedback_message"],
                next_steps=result["next_steps"],
                motivation_quote=result["motivation_quote"],
                progress_analysis=result["progress_analysis"]
            )
            
        except (json.JSONDecodeError, KeyError) as e:
            logger.error(f"JSON parsing failed: {str(e)}")
            raise HTTPException(
                status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
                detail="LLM ì‘ë‹µ íŒŒì‹± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."
            )
        
    except Exception as e:
        logger.error(f"Feedback generation failed: {str(e)}")
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail="í”¼ë“œë°± ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."
        ) 