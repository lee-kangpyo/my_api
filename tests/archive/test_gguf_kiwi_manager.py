#!/usr/bin/env python3
"""
GGUF + Kiwi ì¡°í•© í…ŒìŠ¤íŠ¸ (ModelManager ì‚¬ìš©)
"""

import sys
import os
sys.path.append(os.path.dirname(os.path.dirname(os.path.dirname(__file__))))  # backend í´ë”ë¥¼ ê²½ë¡œì— ì¶”ê°€

import json
import numpy as np
from services.model_manager import model_manager

def test_gguf_kiwi_with_manager():
    """ModelManagerë¥¼ ì‚¬ìš©í•œ GGUF + Kiwi ì¡°í•© í…ŒìŠ¤íŠ¸"""
    
    print("ğŸš€ ModelManagerë¥¼ í†µí•œ GGUF + Kiwi í…ŒìŠ¤íŠ¸ ì‹œì‘")
    print("=" * 50)
    
    try:
        # ModelManagerë¥¼ í†µí•œ ëª¨ë¸ ë¡œë”©
        print("ğŸ“Š ModelManagerë¥¼ í†µí•œ ëª¨ë¸ ì¤€ë¹„ ì¤‘...")
        
        # GGUF ëª¨ë¸ ë° Kiwi ë¶„ì„ê¸° ë¡œë“œ
        gguf_model = model_manager.get_gguf_model()
        kiwi = model_manager.get_kiwi_analyzer()
        
        print("âœ… ëª¨ë“  ëª¨ë¸ ë¡œë“œ ì™„ë£Œ!")
        
        # í…ŒìŠ¤íŠ¸ í…ìŠ¤íŠ¸
        test_texts = [
            "3ê°œì›” ë‚´ì— 5km ëŸ¬ë‹ì„ 30ë¶„ ë‚´ì— ì™„ì£¼í•˜ê¸°",
            "í•œ ë‹¬ ì•ˆì— ì˜ì–´ ë©´ì ‘ ì™„ë²½ ëŒ€ë¹„í•˜ê¸°",
            "íŒŒì´ì¬ í”„ë¡œê·¸ë˜ë° ê¸°ì´ˆë¶€í„° ê³ ê¸‰ê¹Œì§€ ë§ˆìŠ¤í„°í•˜ê¸°"
        ]
        
        print(f"\nğŸ“ í…ŒìŠ¤íŠ¸ í…ìŠ¤íŠ¸ ({len(test_texts)}ê°œ):")
        for i, text in enumerate(test_texts, 1):
            print(f"  {i}. {text}")
        
        # Dense ë²¡í„° ìƒì„± í…ŒìŠ¤íŠ¸
        print(f"\nğŸ”„ Dense ë²¡í„° ìƒì„± ì¤‘...")
        embeddings = []
        
        for i, text in enumerate(test_texts):
            print(f"  ì²˜ë¦¬ ì¤‘: {i+1}/{len(test_texts)}")
            embedding = gguf_model.embed(text)
            embeddings.append(np.array(embedding))
        
        embeddings = np.array(embeddings)
        print(f"âœ… Dense ë²¡í„° ìƒì„± ì™„ë£Œ: {embeddings.shape}")
        
        # Kiwi í‚¤ì›Œë“œ ì¶”ì¶œ í…ŒìŠ¤íŠ¸
        print(f"\nğŸ¥ Kiwi í‚¤ì›Œë“œ ì¶”ì¶œ í…ŒìŠ¤íŠ¸:")
        first_text = test_texts[0]
        
        # í˜•íƒœì†Œ ë¶„ì„ ë° ëª…ì‚¬ ì¶”ì¶œ
        analyzed = kiwi.analyze(first_text)
        nouns = [token.form for token in analyzed[0][0] if token.tag.startswith('N')]
        
        print(f"\n  í…ìŠ¤íŠ¸: {first_text}")
        print(f"  ëª…ì‚¬ ì¶”ì¶œ: {nouns}")
        
        # MariaDB ì €ì¥ í˜•íƒœ ì˜ˆì‹œ
        print(f"\nğŸ’¾ MariaDB ì €ì¥ í˜•íƒœ ì˜ˆì‹œ:")
        dense_for_db = embeddings[0].tolist()
        print(f"  Dense ë²¡í„° ê¸¸ì´: {len(dense_for_db)}")
        print(f"  Dense ë²¡í„° ì°¨ì›: {embeddings.shape[1]}")
        
        sparse_for_db = {
            "keywords": ", ".join(nouns),
            "weights": {noun: 1.0 for noun in nouns},
            "extraction_method": "kiwi",
            "total_tokens": len(kiwi.tokenize(first_text))
        }
        print(f"  Sparse JSON ì˜ˆì‹œ:")
        print(json.dumps(sparse_for_db, indent=2, ensure_ascii=False))
        
        # ìœ ì‚¬ë„ í…ŒìŠ¤íŠ¸
        print(f"\nğŸ¯ ìœ ì‚¬ë„ í…ŒìŠ¤íŠ¸:")
        sim = np.dot(embeddings[0], embeddings[1]) / (
            np.linalg.norm(embeddings[0]) * np.linalg.norm(embeddings[1])
        )
        print(f"  'ëŸ¬ë‹' vs 'ì˜ì–´ë©´ì ‘' ìœ ì‚¬ë„: {sim:.4f}")
        
        # ModelManager ì •ë³´ ì¶œë ¥
        print(f"\nğŸ“Š ModelManager ì •ë³´:")
        model_info = model_manager.get_model_info()
        print(json.dumps(model_info, indent=2, ensure_ascii=False))
        
        print("\n" + "=" * 50)
        print("ğŸ‰ ModelManagerë¥¼ í†µí•œ í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")
        print("âœ… Dense ë²¡í„° ìƒì„± ì„±ê³µ (GGUF)")
        print("âœ… Sparse í‚¤ì›Œë“œ ì¶”ì¶œ ì„±ê³µ (Kiwi)")
        print("âœ… í†µí•© ëª¨ë¸ ê´€ë¦¬ í™•ì¸")
        
        return True
        
    except Exception as e:
        print(f"\nâŒ í…ŒìŠ¤íŠ¸ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        print("ğŸ” ë‹¤ìŒì„ í™•ì¸í•˜ì„¸ìš”:")
        print("   1. ModelManagerê°€ ì •ìƒì ìœ¼ë¡œ ì´ˆê¸°í™”ë˜ì—ˆëŠ”ì§€")
        print("   2. í•„ìš”í•œ íŒ¨í‚¤ì§€ê°€ ëª¨ë‘ ì„¤ì¹˜ë˜ì—ˆëŠ”ì§€")
        print("   3. ì¶©ë¶„í•œ ë©”ëª¨ë¦¬ê°€ ìˆëŠ”ì§€")
        return False

if __name__ == "__main__":
    success = test_gguf_kiwi_with_manager()
    if not success:
        exit(1)
